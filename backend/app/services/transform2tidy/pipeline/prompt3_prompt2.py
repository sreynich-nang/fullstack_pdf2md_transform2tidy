"""
Stage 5: Code Generation - Generate Python cleaning code using prompt3.
LLM-based code generation: Use Gemini to create executable cleaning scripts.

Input: prompt3 template + profile_raw_df + strategy
Output: Python files (document_name/prompt3_py1.py, prompt3_py2.py, ...)

# Core workflow flow:
Profile JSON (from temp/profile_raw_df/)
    ↓
Strategy Markdown (from temp/prompt2_prompt1/)
    ↓
<PROFILE_JSON> + <PROMPT2_OUTPUT> variables
    ↓
render_prompt(PROMPT_3_FILE, variables)  # Core task
    ↓
Gemini API
    ↓
Save to temp/prompt3_prompt2/{doc_name}/
"""

import json
import logging
import sys
from pathlib import Path
from typing import List

import google.generativeai as genai

PROJECT_ROOT = Path(__file__).resolve().parents[4]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from app.services.transform2tidy.pipeline.settings import (
    PROMPT2_PROMPT1_DIR,
    PROMPT3_PROMPT2_DIR,
    get_llm_config,
)
from app.utils.prompt_loader import load_prompt, render_prompt


logger = logging.getLogger(__name__)
PROMPT3_TEMPLATE = load_prompt("prompt_3_generate_cleaning_code.md")


def generate_cleaning_code(
    api_key: str,
    model: str,
    temperature: float,
    max_tokens: int,
    table_profile: dict,
    strategy_content: str
) -> str:
    
    # Configure Gemini
    genai.configure(api_key=api_key)
    
    # CORE TASK: Prepare flexible variables and render prompt with profile JSON and strategy
    variables = {
        "PROFILE_JSON": table_profile,          # Main variable: Profile JSON from temp/profile_raw_df/
        "PROMPT2_OUTPUT": strategy_content,     # Main variable: Strategy markdown from temp/prompt2_prompt1/
        "language": "python",
        "framework": "pandas"
    }
    
    # Render prompt: render_prompt(PROMPT_3_FILE, PROFILE_JSON + PROMPT2_OUTPUT + other variables)
    try:
        rendered_prompt = render_prompt(PROMPT3_TEMPLATE, variables, strict=False)
    except Exception:
        logger.warning("Falling back to raw prompt3 template")
        rendered_prompt = PROMPT3_TEMPLATE
    
    # Call Gemini API with rendered prompt
    model_obj = genai.GenerativeModel(model)
    response = model_obj.generate_content(
        rendered_prompt,
        generation_config={
            "temperature": temperature,
            "max_output_tokens": max_tokens,
        }
    )
    
    # Extract code from response (remove markdown code blocks if present)
    code = response.text
    if code.startswith("```python"):
        code = code[9:]  # Remove ```python
    if code.startswith("```"):
        code = code[3:]  # Remove ```
    if code.endswith("```"):
        code = code[:-3]  # Remove trailing ```
    
    return code.strip()


def save_code_as_python(
    code: str,
    output_dir: Path,
    doc_name: str,
    table_num: int
) -> Path:
    
    doc_subdir = output_dir / doc_name
    doc_subdir.mkdir(parents=True, exist_ok=True)
    
    py_path = doc_subdir / f"prompt3_py{table_num}.py"
    
    with open(py_path, "w", encoding="utf-8") as f:
        # Add header with description
        f.write("# Auto-generated table cleaning code\n")
        f.write(f"# Table #{table_num}\n")
        f.write("# Generated by LLM based on table analysis\n\n")
        f.write("import pandas as pd\n\n")
        f.write(code)
        f.write("\n")
    
    return py_path


def process_tables_with_prompt3(
    api_key: str,
    model: str,
    temperature: float,
    max_tokens: int,
    profile_json_paths: List[Path],
    strategy_md_paths: List[Path],
    output_dir: Path,
    doc_name: str
) -> List[Path]:
    
    import re

    result_paths = []
    
    for profile_path, strategy_path in zip(profile_json_paths, strategy_md_paths):
        # Extract table number from filename (e.g., profile_table11.json -> 11)
        # Default fallback
        table_num = len(result_paths) + 1
        
        # Robust regex extraction to handle profile_table5.json, table5_profile.json
        match = re.search(r"table(\d+)", profile_path.stem)
        if match:
            table_num = int(match.group(1))

        # Load profile JSON from temp/profile_raw_df/{doc_name}/profile_table{N}.json
        with open(profile_path, "r", encoding="utf-8") as f:
            profile = json.load(f)
        
        # Load strategy markdown from temp/prompt2_prompt1/{doc_name}/prompt2_table{N}.md
        with open(strategy_path, "r", encoding="utf-8") as f:
            strategy_content = f.read()
        
        # Core task: Generate code using render_prompt() with PROMPT_3_FILE and both flexible variables
        code = generate_cleaning_code(
            api_key=api_key,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            table_profile=profile,          # Flexible variable: profile JSON from temp/profile_raw_df/
            strategy_content=strategy_content  # Flexible variable: strategy MD from temp/prompt2_prompt1/
        )
        
        # Save code to temp/prompt3_prompt2/{doc_name}/prompt3_py{N}.py
        result_path = save_code_as_python(code, output_dir, doc_name, table_num)
        result_paths.append(result_path)
    
    return result_paths

if __name__ == "__main__":
    import argparse

    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    parser = argparse.ArgumentParser(description="Generate cleaning code using prompt3.")
    parser.add_argument("input_files", nargs="+", type=Path, help="Input files (mix of .json profiles and .md strategies)")
    parser.add_argument("--output-dir", type=Path, default=PROMPT3_PROMPT2_DIR, help="Output directory for Python files")

    args = parser.parse_args()
    output_dir = args.output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    llm_cfg = get_llm_config()

    profile_paths: List[Path] = []
    strategy_paths: List[Path] = []

    for path in args.input_files:
        if not path.exists():
            logger.warning("File not found: %s", path)
            continue

        if path.suffix.lower() == ".json":
            profile_paths.append(path)
        elif path.suffix.lower() == ".md":
            strategy_paths.append(path)
        else:
            logger.warning("Ignored file with unknown extension: %s", path)

    profile_paths.sort()
    strategy_paths.sort()

    if len(profile_paths) != len(strategy_paths):
        logger.warning(
            "Mismatch in number of files: %s profiles vs %s strategies.",
            len(profile_paths),
            len(strategy_paths),
        )
        logger.warning("Files will be paired in sorted order. Excess files will be ignored.")

    doc_name = "unknown_doc"
    if profile_paths:
        doc_name = profile_paths[0].parent.name
    elif strategy_paths:
        doc_name = strategy_paths[0].parent.name

    pair_count = min(len(profile_paths), len(strategy_paths))
    if pair_count == 0:
        logger.error("No valid input pairs found.")
        sys.exit(1)

    logger.info("Processing %s pairs for document '%s'...", pair_count, doc_name)

    output_paths = process_tables_with_prompt3(
        api_key=llm_cfg.api_key,
        model=llm_cfg.model,
        temperature=llm_cfg.temperature,
        max_tokens=llm_cfg.max_tokens,
        profile_json_paths=profile_paths[:pair_count],
        strategy_md_paths=strategy_paths[:pair_count],
        output_dir=output_dir,
        doc_name=doc_name,
    )

    logger.info("Generated %s code files in %s", len(output_paths), output_dir / doc_name)
